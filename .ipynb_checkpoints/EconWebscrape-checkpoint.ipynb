{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EconWebscrape.ipynb\n",
    "'''\n",
    "    Author: Kevin Yao (email: kevinxy00@gmail.com)\n",
    "\n",
    "    Purpose: To get abstracts from the top 10 Economics Journals,\n",
    "    in terms of impact factors for the last 10 years. \n",
    "    To accomplish this, I will webscrape \n",
    "    https://ideas.repec.org/top/top.journals.simple10.html\n",
    "    for links to each journal stored on the site. \n",
    "'''\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple Impact Factors (Last 10 Years) for Journals:\n",
    "''' gets the html from ideas.repec.org\n",
    "    This webpage contains the link to each journals,\n",
    "    which we will need to get the abstracts \n",
    "'''\n",
    "\n",
    "base_url = \"https://ideas.repec.org\"\n",
    "journs_route = \"/top/top.journals.simple10.html\"\n",
    "url = base_url + journs_route\n",
    "\n",
    "r = requests.get(url)\n",
    "data = r.text # turns response into texts\n",
    "soup = BeautifulSoup(data, \"html.parser\") # changes the response from text to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_topList = soup.find(class_=\"toplist\")\n",
    "soup_href = soup_topList.find_all(\"a\", href=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://ideas.repec.org/s/oup/qjecon.html\n",
      "2 https://ideas.repec.org/s/aea/jeclit.html\n",
      "3 https://ideas.repec.org/s/aea/aejmac.html\n",
      "4 https://ideas.repec.org/s/wly/emetrp.html\n",
      "5 https://ideas.repec.org/s/ecm/emetrp.html\n",
      "6 https://ideas.repec.org/s/aea/aejapp.html\n",
      "7 https://ideas.repec.org/s/ucp/jpolec.html\n",
      "8 https://ideas.repec.org/s/oup/restud.html\n",
      "9 https://ideas.repec.org/s/bla/jfinan.html\n",
      "10 https://ideas.repec.org/s/oup/ecpoli.html\n",
      "11 https://ideas.repec.org/s/bla/ecpoli.html\n",
      "12 https://ideas.repec.org/s/oup/jeurec.html\n",
      "13 https://ideas.repec.org/s/bla/jeurec.html\n",
      "14 https://ideas.repec.org/s/tpr/jeurec.html\n"
     ]
    }
   ],
   "source": [
    "# get list of links to the top 10 journals \n",
    "''' \n",
    "NOTE: (includes occasional multiple links to same journal at different times)\n",
    "# e.g. https://ideas.repec.org/s/wly/emetrp.html (Econometrica from sep. 2014 to present)\n",
    "vs https://ideas.repec.org/s/ecm/emetrp.html (Econometrica from 1950 to Nov. 2013)\n",
    "'''\n",
    "number = 0\n",
    "journ_ls = []\n",
    "for entry in range(0, 14):\n",
    "    number = number + 1\n",
    "    base_link = soup_href[entry][\"href\"]\n",
    "    url = base_url + base_link\n",
    "    print(number, url)\n",
    "    journ_ls.append(url)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "    Function for getting a list of links to journal articles \n",
    "    from the first page of a journal\n",
    "'''\n",
    "def get_article_links(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "    # page is broken up into lists for each volume/issue\n",
    "    # this gets the raw text of each page\n",
    "    soup_issues = soup.find_all(class_=\"list-group paperlist\")\n",
    "    \n",
    "    # this converts raw text into links by finding href\n",
    "    number = 0\n",
    "    issues_link_ls = []\n",
    "    for issue in soup_issues:\n",
    "        soup_issues_link = issue.find_all(\"a\", href=True)\n",
    "        for link in soup_issues_link:\n",
    "            number = number + 1\n",
    "            base_link = link[\"href\"]\n",
    "            url = base_url + base_link\n",
    "            print(number, url)\n",
    "            issues_link_ls.append(url)\n",
    "\n",
    "    return issues_link_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "# Test for above section: for number 1 article (journal of quarterly economics),\n",
    "# get list of all hrefs\n",
    "number = 0\n",
    "issues_link_ls = []\n",
    "for issue in soup_issues:\n",
    "    soup_issues_link = issue.find_all(\"a\", href=True)\n",
    "    for link in soup_issues_link:\n",
    "        number = number + 1\n",
    "        base_link = link[\"href\"]\n",
    "        url = base_url + base_link\n",
    "        print(number, url)\n",
    "        issues_link_ls.append(url)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# preliminary TEST for TEST: get abstract \n",
    "r = requests.get(issues_link_ls[0])\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "soup_abstract = soup.find(id = \"abstract-body\")\n",
    "print(soup_abstract.text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# TEST for getting the abstract from each issues link for the first journal\n",
    "abstract_ls = []\n",
    "for url in issues_link_ls:\n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    soup_abstract = soup.find(id = \"abstract-body\")\n",
    "    abstract_ls.append(soup_abstract.text)\n",
    "    # sleep for 1 second in between requests so webpage doesn't hate me too much\n",
    "    time.sleep(1) \n",
    "abstract_ls\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PUTTING IT ALL TOGETHER\n",
    "\n",
    "''' For each journal in the journal list of the top 10 journals, get list of url of articles\n",
    "    for the first page of each journal. Then using those url, get the abstract for each article.\n",
    "    Save to a list\n",
    "'''\n",
    "def get_abstracts(ls):\n",
    "    abstract_ls = []\n",
    "    journ_count = 0\n",
    "    art_count = 0\n",
    "    for journal_url in ls:\n",
    "        article_links_ls = get_article_links(journal_url)\n",
    "        journ_count = journ_count + 1\n",
    "        print(\"****** Processing Journal # \" + str(journ_count) + \" ******\")\n",
    "        for url in article_links_ls:\n",
    "            art_count = art_count + 1\n",
    "            print(str(art_count))\n",
    "            r = requests.get(url)\n",
    "            data = r.text\n",
    "            soup = BeautifulSoup(data, \"html.parser\")\n",
    "            soup_abstract = soup.find(id = \"abstract-body\")\n",
    "            abstract_ls.append(soup_abstract.text)\n",
    "            time.sleep(.25)\n",
    "        # sleep in between each journal so webpage doesn't hate me too much\n",
    "        time.sleep(40) \n",
    "        print(\"resting for a moment so webpage doesn't hate me too much\")\n",
    "    return abstract_ls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    **************************************************************************\n",
    "    Finding the top 10 or so Econ journal abstracts in terms of impact factor\n",
    "    according to https://ideas.repec.org.\n",
    "    \n",
    "    Runtime: estimated to be 21 mins (1.5 minutes per journal, 14 journals including\n",
    "    occasional links to the same journal at different times)\n",
    "    **************************************************************************\n",
    "\n",
    "note: output cleared for brevity.\n",
    "'''\n",
    "abstract_ls = get_abstracts(journ_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get rid entries where abstracts are not available\n",
    "for entry in abstract_ls:\n",
    "    if entry == 'No abstract is available for this item.':\n",
    "        abstract_ls.remove(entry)\n",
    "        \n",
    "len(abstract_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save list of abstracts to dataframe\n",
    "abstract_df = pd.DataFrame(abstract_ls, columns=[\"abstract\"])\n",
    "abstract_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv file \n",
    "abstract_df.to_csv(r'raw_data_econ/topJournals_abstract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting journals rank 11-20, in case we need it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://ideas.repec.org/s/aea/aecrev.html\n",
      "2 https://ideas.repec.org/s/bin/bpeajo.html\n",
      "3 https://ideas.repec.org/s/tpr/restat.html\n",
      "4 https://ideas.repec.org/s/aea/jecper.html\n",
      "5 https://ideas.repec.org/s/oup/rfinst.html\n",
      "6 https://ideas.repec.org/s/kap/jecgro.html\n",
      "7 https://ideas.repec.org/s/eee/moneco.html\n",
      "8 https://ideas.repec.org/s/eee/crcspp.html\n",
      "9 https://ideas.repec.org/s/eee/jfinec.html\n",
      "10 https://ideas.repec.org/s/anr/reveco.html\n",
      "11 https://ideas.repec.org/s/now/fnteco.html\n",
      "12 https://ideas.repec.org/s/wly/econjl.html\n",
      "13 https://ideas.repec.org/s/ecj/econjl.html\n"
     ]
    }
   ],
   "source": [
    "''' Getting journals url, including same journals at multiple time \n",
    "periods as laid out in the webpage. '''\n",
    "number = 0\n",
    "journ_ls = []\n",
    "for entry in range(14, 27):\n",
    "    number = number + 1\n",
    "    base_link = soup_href[entry][\"href\"]\n",
    "    url = base_url + base_link\n",
    "    print(number, url)\n",
    "    journ_ls.append(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "*********************************************\n",
    "Getting journals rank 11-20 by impact factors over 10 years.\n",
    "\n",
    "Estimated run time: 19.5 minutes (now set sleep to .25 seconds between articles\n",
    "(primarily 200 articles per journal) and 40 seconds between journals (13 nondistinct))\n",
    "note: output cleared for brevity.\n",
    "*********************************************\n",
    "'''\n",
    "abstract_ls = get_abstracts(journ_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get rid entries where abstracts are not available\n",
    "for entry in abstract_ls:\n",
    "    if entry == 'No abstract is available for this item.':\n",
    "        abstract_ls.remove(entry)\n",
    "        \n",
    "# len(abstract_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How large are the benefits of transportation i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Macro developments leading up to the 2008 cris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper provides a simple, yet robust frame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We establish the importance of team-specific c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We document substantial increases in agricultu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0  How large are the benefits of transportation i...\n",
       "1  Macro developments leading up to the 2008 cris...\n",
       "2  This paper provides a simple, yet robust frame...\n",
       "3  We establish the importance of team-specific c...\n",
       "4  We document substantial increases in agricultu..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save list of abstracts to dataframe\n",
    "abstract_df = pd.DataFrame(abstract_ls, columns=[\"abstract\"])\n",
    "abstract_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv file \n",
    "abstract_df.to_csv(r'raw_data_econ/hiRankJournals_abstract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the \"Not top journals\" abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122,  71, 112,  34, 126,  91,  80,  40, 122, 102])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    For the journals not at the top, random sampling is used to generate a list of\n",
    "    ranks between 20 and 100, with the 127th web scraped href being a link to rank 100. \n",
    "'''\n",
    "np.random.seed(42)\n",
    "random_ranks = np.random.randint(20, 127, 10)\n",
    "random_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://ideas.repec.org/s/bla/germec.html\n",
      "2 https://ideas.repec.org/s/aea/aejmic.html\n",
      "3 https://ideas.repec.org/s/ucp/ecdecc.html\n",
      "4 https://ideas.repec.org/s/ucp/jlabec.html\n",
      "5 https://ideas.repec.org/s/pia/review.html\n",
      "6 https://ideas.repec.org/s/aen/journl.html\n",
      "7 https://ideas.repec.org/s/cup/jfinqa.html\n",
      "8 https://ideas.repec.org/s/mcb/jmoncb.html\n",
      "9 https://ideas.repec.org/s/bla/germec.html\n",
      "10 https://ideas.repec.org/s/ekn/ekonom.html\n"
     ]
    }
   ],
   "source": [
    "number = 0\n",
    "journ_ls = []\n",
    "for entry in random_ranks:\n",
    "    number = number + 1\n",
    "    base_link = soup_href[entry][\"href\"]\n",
    "    url = base_url + base_link\n",
    "    print(number, url)\n",
    "    journ_ls.append(url)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*********************************************\n",
    "Getting random sample of journals rank 20-100 by impact factors over 10 years.\n",
    "\n",
    "Estimated run time: 19.5 minutes (now set sleep to .25 seconds between articles\n",
    "(primarily 200 articles per journal) and 40 seconds between journals (13 nondistinct))\n",
    "note: output cleared for brevity.\n",
    "*********************************************\n",
    "'''\n",
    "abstract_ls = get_abstracts(journ_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid entries where abstracts are not available\n",
    "for entry in abstract_ls:\n",
    "    if entry == 'No abstract is available for this item.':\n",
    "        abstract_ls.remove(entry)\n",
    "    if entry[0:12] == ' type=\"main\"':\n",
    "        entry = entry[41:]\n",
    "        \n",
    "len(abstract_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We conducted six treatments of a standard mora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper analyzes blindfolded versus informe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We analyze the drivers of the size of the audi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Japan has been in a benign liquidity trap sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This paper addresses tax loopholes that allow ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract\n",
       "0  We conducted six treatments of a standard mora...\n",
       "1  This paper analyzes blindfolded versus informe...\n",
       "2  We analyze the drivers of the size of the audi...\n",
       "3  Japan has been in a benign liquidity trap sinc...\n",
       "4  This paper addresses tax loopholes that allow ..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save list of abstracts to dataframe\n",
    "abstract_df = pd.DataFrame(abstract_ls, columns=[\"abstract\"])\n",
    "abstract_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstract    We study how subjects in an experiment use dif...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of beginnings which start with ' type=\"main\"'\n",
    "for index, row in abstract_df.iterrows():\n",
    "    if row[\"abstract\"][0:12] == ' type=\"main\"':\n",
    "        row[\"abstract\"] = row[\"abstract\"][41:]\n",
    "\n",
    "abstract_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to csv file \n",
    "abstract_df.to_csv(r'raw_data_econ/notHiJournals_abstract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More data for not top rank journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24,  82, 110,  35,  81,  43,  64,  70,  28,  48,  24, 109,  51,\n",
       "        89,  21,  59,  23, 108,  75,  23])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    For the journals not at the top, random sampling is used to generate a list of\n",
    "    ranks between 20 and 100, with the 127th web scraped href being a link to rank 100. \n",
    "'''\n",
    "np.random.seed(25)\n",
    "random_ranks2 = np.random.randint(20, 127, 20)\n",
    "\n",
    "for item in random_ranks2:\n",
    "    if item in random_ranks:\n",
    "        random_ranks2.drop(item)\n",
    "        \n",
    "random_ranks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://ideas.repec.org/s/now/fnteco.html\n",
      "2 https://ideas.repec.org/s/ags/ajaeap.html\n",
      "3 https://ideas.repec.org/s/rpo/leanco.html\n",
      "4 https://ideas.repec.org/s/eee/jfinin.html\n",
      "5 https://ideas.repec.org/s/eee/respol.html\n",
      "6 https://ideas.repec.org/s/eee/pubeco.html\n",
      "7 https://ideas.repec.org/s/eee/jimfin.html\n",
      "8 https://ideas.repec.org/s/oup/wbecrv.html\n",
      "9 https://ideas.repec.org/s/aea/aejpol.html\n",
      "10 https://ideas.repec.org/s/ijc/ijcjou.html\n",
      "11 https://ideas.repec.org/s/now/fnteco.html\n",
      "12 https://ideas.repec.org/s/eee/enepol.html\n",
      "13 https://ideas.repec.org/s/wly/quante.html\n",
      "14 https://ideas.repec.org/s/spr/weltar.html\n",
      "15 https://ideas.repec.org/s/eee/crcspp.html\n",
      "16 https://ideas.repec.org/s/eee/jeeman.html\n",
      "17 https://ideas.repec.org/s/anr/reveco.html\n",
      "18 https://ideas.repec.org/s/now/jirere.html\n",
      "19 https://ideas.repec.org/s/eee/finsta.html\n",
      "20 https://ideas.repec.org/s/anr/reveco.html\n"
     ]
    }
   ],
   "source": [
    "number = 0\n",
    "journ_ls = []\n",
    "for entry in random_ranks2:\n",
    "    number = number + 1\n",
    "    base_link = soup_href[entry][\"href\"]\n",
    "    url = base_url + base_link\n",
    "    print(number, url)\n",
    "    journ_ls.append(url)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 https://ideas.repec.org/a/now/fnteco/0800000033.html\n",
      "2 https://ideas.repec.org/a/now/fnteco/0800000030.html\n",
      "3 https://ideas.repec.org/a/now/fnteco/0800000026.html\n",
      "4 https://ideas.repec.org/a/now/fnteco/0800000023.html\n",
      "5 https://ideas.repec.org/a/now/fnteco/0800000028.html\n",
      "6 https://ideas.repec.org/a/now/fnteco/0800000022.html\n",
      "7 https://ideas.repec.org/a/now/fnteco/0800000019.html\n",
      "8 https://ideas.repec.org/a/now/fnteco/0800000018.html\n",
      "9 https://ideas.repec.org/a/now/fnteco/0800000017.html\n",
      "10 https://ideas.repec.org/a/now/fnteco/0800000020.html\n",
      "11 https://ideas.repec.org/a/now/fnteco/0800000011.html\n",
      "12 https://ideas.repec.org/a/now/fnteco/0800000016.html\n",
      "13 https://ideas.repec.org/a/now/fnteco/0800000014.html\n",
      "14 https://ideas.repec.org/a/now/fnteco/0800000015.html\n",
      "15 https://ideas.repec.org/a/now/fnteco/0800000013.html\n",
      "16 https://ideas.repec.org/a/now/fnteco/0800000010.html\n",
      "17 https://ideas.repec.org/a/now/fnteco/0800000002.html\n",
      "18 https://ideas.repec.org/a/now/fnteco/0800000009.html\n",
      "19 https://ideas.repec.org/a/now/fnteco/0800000004.html\n",
      "20 https://ideas.repec.org/a/now/fnteco/0800000008.html\n",
      "21 https://ideas.repec.org/a/now/fnteco/0800000005.html\n",
      "****** Processing Journal # 1 ******\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "resting for a moment so webpage doesn't hate me too much\n",
      "1 https://ideas.repec.org/a/ags/ajaeap/164216.html\n",
      "2 https://ideas.repec.org/a/ags/ajaeap/164213.html\n",
      "3 https://ideas.repec.org/a/ags/ajaeap/164214.html\n",
      "4 https://ideas.repec.org/a/ags/ajaeap/164215.html\n",
      "5 https://ideas.repec.org/a/ags/ajaeap/164203.html\n",
      "6 https://ideas.repec.org/a/ags/ajaeap/164204.html\n",
      "7 https://ideas.repec.org/a/ags/ajaeap/164205.html\n",
      "8 https://ideas.repec.org/a/ags/ajaeap/164206.html\n",
      "9 https://ideas.repec.org/a/ags/ajaeap/164208.html\n",
      "10 https://ideas.repec.org/a/ags/ajaeap/164209.html\n",
      "11 https://ideas.repec.org/a/ags/ajaeap/164210.html\n",
      "12 https://ideas.repec.org/a/ags/ajaeap/164211.html\n",
      "13 https://ideas.repec.org/a/ags/ajaeap/164212.html\n",
      "14 https://ideas.repec.org/a/ags/ajaeap/164192.html\n",
      "15 https://ideas.repec.org/a/ags/ajaeap/164193.html\n",
      "16 https://ideas.repec.org/a/ags/ajaeap/164194.html\n",
      "17 https://ideas.repec.org/a/ags/ajaeap/164195.html\n",
      "18 https://ideas.repec.org/a/ags/ajaeap/164196.html\n",
      "19 https://ideas.repec.org/a/ags/ajaeap/164200.html\n",
      "20 https://ideas.repec.org/a/ags/ajaeap/164071.html\n",
      "21 https://ideas.repec.org/a/ags/ajaeap/164072.html\n",
      "22 https://ideas.repec.org/a/ags/ajaeap/164073.html\n",
      "23 https://ideas.repec.org/a/ags/ajaeap/164074.html\n",
      "24 https://ideas.repec.org/a/ags/ajaeap/164075.html\n",
      "25 https://ideas.repec.org/a/ags/ajaeap/164076.html\n",
      "26 https://ideas.repec.org/a/ags/ajaeap/164062.html\n",
      "27 https://ideas.repec.org/a/ags/ajaeap/164063.html\n",
      "28 https://ideas.repec.org/a/ags/ajaeap/164064.html\n",
      "29 https://ideas.repec.org/a/ags/ajaeap/164065.html\n",
      "30 https://ideas.repec.org/a/ags/ajaeap/164066.html\n",
      "31 https://ideas.repec.org/a/ags/ajaeap/164067.html\n",
      "32 https://ideas.repec.org/a/ags/ajaeap/164068.html\n",
      "33 https://ideas.repec.org/a/ags/ajaeap/164069.html\n",
      "34 https://ideas.repec.org/a/ags/ajaeap/164070.html\n",
      "35 https://ideas.repec.org/a/ags/ajaeap/164022.html\n",
      "36 https://ideas.repec.org/a/ags/ajaeap/164024.html\n",
      "37 https://ideas.repec.org/a/ags/ajaeap/164025.html\n",
      "38 https://ideas.repec.org/a/ags/ajaeap/164026.html\n",
      "39 https://ideas.repec.org/a/ags/ajaeap/164027.html\n",
      "40 https://ideas.repec.org/a/ags/ajaeap/164029.html\n",
      "41 https://ideas.repec.org/a/ags/ajaeap/164030.html\n",
      "42 https://ideas.repec.org/a/ags/ajaeap/164031.html\n",
      "43 https://ideas.repec.org/a/ags/ajaeap/164032.html\n",
      "44 https://ideas.repec.org/a/ags/ajaeap/164033.html\n",
      "45 https://ideas.repec.org/a/ags/ajaeap/45710.html\n",
      "46 https://ideas.repec.org/a/ags/ajaeap/45711.html\n",
      "47 https://ideas.repec.org/a/ags/ajaeap/164017.html\n",
      "48 https://ideas.repec.org/a/ags/ajaeap/164019.html\n",
      "49 https://ideas.repec.org/a/ags/ajaeap/164020.html\n",
      "50 https://ideas.repec.org/a/ags/ajaeap/164021.html\n",
      "51 https://ideas.repec.org/a/ags/ajaeap/7042.html\n",
      "52 https://ideas.repec.org/a/ags/ajaeap/7043.html\n",
      "53 https://ideas.repec.org/a/ags/ajaeap/7045.html\n",
      "54 https://ideas.repec.org/a/ags/ajaeap/7089.html\n",
      "55 https://ideas.repec.org/a/ags/ajaeap/7090.html\n",
      "56 https://ideas.repec.org/a/ags/ajaeap/7091.html\n",
      "57 https://ideas.repec.org/a/ags/ajaeap/7092.html\n",
      "58 https://ideas.repec.org/a/ags/ajaeap/7093.html\n",
      "59 https://ideas.repec.org/a/ags/ajaeap/7094.html\n",
      "60 https://ideas.repec.org/a/ags/ajaeap/7095.html\n",
      "61 https://ideas.repec.org/a/ags/ajaeap/7104.html\n",
      "62 https://ideas.repec.org/a/ags/ajaeap/7105.html\n",
      "63 https://ideas.repec.org/a/ags/ajaeap/7106.html\n",
      "64 https://ideas.repec.org/a/ags/ajaeap/7107.html\n",
      "65 https://ideas.repec.org/a/ags/ajaeap/7108.html\n",
      "66 https://ideas.repec.org/a/ags/ajaeap/7109.html\n",
      "67 https://ideas.repec.org/a/ags/ajaeap/97150.html\n",
      "68 https://ideas.repec.org/a/ags/ajaeap/7072.html\n",
      "69 https://ideas.repec.org/a/ags/ajaeap/7073.html\n",
      "70 https://ideas.repec.org/a/ags/ajaeap/7096.html\n",
      "71 https://ideas.repec.org/a/ags/ajaeap/7097.html\n",
      "72 https://ideas.repec.org/a/ags/ajaeap/7098.html\n",
      "73 https://ideas.repec.org/a/ags/ajaeap/7099.html\n",
      "74 https://ideas.repec.org/a/ags/ajaeap/7100.html\n",
      "75 https://ideas.repec.org/a/ags/ajaeap/7101.html\n",
      "76 https://ideas.repec.org/a/ags/ajaeap/7102.html\n",
      "77 https://ideas.repec.org/a/ags/ajaeap/7103.html\n",
      "78 https://ideas.repec.org/a/ags/ajaeap/7404.html\n",
      "79 https://ideas.repec.org/a/ags/ajaeap/7405.html\n",
      "80 https://ideas.repec.org/a/ags/ajaeap/7406.html\n",
      "81 https://ideas.repec.org/a/ags/ajaeap/7407.html\n",
      "82 https://ideas.repec.org/a/ags/ajaeap/7408.html\n",
      "83 https://ideas.repec.org/a/ags/ajaeap/7409.html\n",
      "84 https://ideas.repec.org/a/ags/ajaeap/60954.html\n",
      "85 https://ideas.repec.org/a/ags/ajaeap/7410.html\n",
      "86 https://ideas.repec.org/a/ags/ajaeap/7411.html\n",
      "87 https://ideas.repec.org/a/ags/ajaeap/7412.html\n",
      "88 https://ideas.repec.org/a/ags/ajaeap/7413.html\n",
      "89 https://ideas.repec.org/a/ags/ajaeap/7414.html\n",
      "90 https://ideas.repec.org/a/ags/ajaeap/7415.html\n",
      "91 https://ideas.repec.org/a/ags/ajaeap/7416.html\n",
      "92 https://ideas.repec.org/a/ags/ajaeap/7417.html\n",
      "93 https://ideas.repec.org/a/ags/ajaeap/7418.html\n",
      "94 https://ideas.repec.org/a/ags/ajaeap/7419.html\n",
      "95 https://ideas.repec.org/a/ags/ajaeap/7393.html\n",
      "96 https://ideas.repec.org/a/ags/ajaeap/7394.html\n",
      "97 https://ideas.repec.org/a/ags/ajaeap/7395.html\n",
      "98 https://ideas.repec.org/a/ags/ajaeap/7396.html\n",
      "99 https://ideas.repec.org/a/ags/ajaeap/7397.html\n",
      "100 https://ideas.repec.org/a/ags/ajaeap/7398.html\n",
      "101 https://ideas.repec.org/a/ags/ajaeap/7399.html\n",
      "102 https://ideas.repec.org/a/ags/ajaeap/7400.html\n",
      "103 https://ideas.repec.org/a/ags/ajaeap/7401.html\n",
      "104 https://ideas.repec.org/a/ags/ajaeap/7402.html\n",
      "105 https://ideas.repec.org/a/ags/ajaeap/7403.html\n",
      "****** Processing Journal # 2 ******\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "resting for a moment so webpage doesn't hate me too much\n",
      "1 https://ideas.repec.org/a/rpo/leanco/2012.html\n",
      "2 https://ideas.repec.org/a/rpo/leanco/2011.html\n",
      "3 https://ideas.repec.org/a/rpo/leanco/2009.html\n",
      "4 https://ideas.repec.org/a/rpo/leanco/2008.html\n",
      "5 https://ideas.repec.org/a/rpo/leanco/2007.html\n",
      "6 https://ideas.repec.org/a/rpo/leanco/2006.html\n",
      "7 https://ideas.repec.org/a/rpo/leanco/2005.html\n",
      "8 https://ideas.repec.org/a/rpo/leanco/2004.html\n",
      "9 https://ideas.repec.org/a/rpo/leanco/2003.html\n",
      "10 https://ideas.repec.org/a/rpo/leanco/2002.html\n",
      "11 https://ideas.repec.org/a/rpo/leanco/2001.html\n",
      "12 https://ideas.repec.org/a/rpo/leanco/2000.html\n",
      "****** Processing Journal # 3 ******\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "*********************************************\n",
    "Getting random sample of journals rank 20-100 by impact factors over 10 years.\n",
    "\n",
    "Estimated run time: 39 minutes (now set sleep to .25 seconds between articles\n",
    "(primarily 200 articles per journal) and 40 seconds between journals (20 nondistinct))\n",
    "\n",
    "*********************************************\n",
    "'''\n",
    "abstract_ls = get_abstracts(journ_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get rid entries where abstracts are not available\n",
    "for entry in abstract_ls:\n",
    "    if entry == 'No abstract is available for this item.':\n",
    "        abstract_ls.remove(entry)\n",
    "    if entry[0:12] == ' type=\"main\"':\n",
    "        entry = entry[41:]\n",
    "        \n",
    "len(abstract_ls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
